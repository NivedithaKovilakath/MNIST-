# -*- coding: utf-8 -*-
"""mnist_SVM_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zto9SR0rrVKVmSdS6I0erIXfksOMdY0q
"""

import numpy as np
import tensorflow as tf
import keras

#importing MNIST dataset

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

#Forming arrays for the input and output data

x_train=np.array(x_train)
x_test=np.array(x_test)

y_train=np.array(y_train)
y_test=np.array(y_test)

#to flatten the arrays

l=len(x_train)

x_train=x_train.reshape(l,-1)


m=len(x_test)
x_test=x_test.reshape(m,-1)

#slice

x_train=x_train[:1000]
x_test=x_test[:1000]
y_train=y_train[:1000]
y_test=y_test[:1000]

class SVM:

  def __init__(self, C=1.0):
    self.C=C
    self.W=0
    self.B=0

  def hinge_loss(self, W, B, X, Y):
    loss=[]
    l_= .5 * np.dot(W, W.T)
    for i in range(X.shape[0]):
      ti=Y[i]*(np.dot(X[i], W.T)+ B)
      a= self.C * (max(0, 1-ti))
      for j in range(len(a)):
        loss[j]+= a[j]+l_
    
    return loss


  def fit(self, X, Y, batch_size=100, learning=0.001, epochs=10):
    features=X.shape[1]
    samples=X.shape[0]
    n=learning
    C=self.C
    W=np.zeros((10,features))
    bias=np.zeros((1,10))
    losses=[]
    
   # for i in range(epochs):
    l=self.hinge_loss(W, bias, X, Y)
    losses.append(l)
    
    for batch_start in range(0, samples, batch_size):
      gradw=0
      gradb=0
      
      for j in range(batch_start, batch_start+ batch_size):
        ti=Y[j]*(np.dot(X[j], W)+bias)
        if ti>1:
          gradw +=0
          gradb +=0

        else:
          gradw += C*Y[j]*X[j]
          gradb += C*Y[j]

      W=W -n*W + n+gradw
      bias=bias+ n*gradb

    self.W=W
    self.B=bias
    return self.W,self.B, losses

  def softmax(self, x):
    exps=np.exp(x-x.max())
    return exps/np.sum(exps, axis=0)


  def predict(self, X, W,B):
    z=np.dot(X, W.T)+B
    return self.softmax(z)

  def model(self, X_train, Y_train, X_test, Y_test, epochs=1):
    for i in range(epochs):
      W,B, losses= self.fit(x_train, y_train)
      predictions=[]
      for x, y in zip(x_test, y_test):
        output=self.predict(x, W, B)
        print((output))
        #pred=np.argmax(output)
        #predictions.append(pred==np.argmax(y))

svm=SVM()
svm.model(x_train, y_train, x_test, y_test)